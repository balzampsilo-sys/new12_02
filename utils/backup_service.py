"""–°–µ—Ä–≤–∏—Å —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –ë–î"""

import gzip
import logging
import shutil
import sqlite3
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Optional


class BackupService:
    """
    –°–µ—Ä–≤–∏—Å –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è SQLite –ë–î.

    Features:
    - –°–∂–∞—Ç–∏–µ –±—ç–∫–∞–ø–æ–≤ —á–µ—Ä–µ–∑ gzip
    - –†–æ—Ç–∞—Ü–∏—è —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤
    - –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–∑ –±—ç–∫–∞–ø–∞
    - –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
    """

    def __init__(self, db_path: str, backup_dir: str, retention_days: int = 30):
        """
        Args:
            db_path: –ü—É—Ç—å –∫ SQLite –ë–î
            backup_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –±—ç–∫–∞–ø–æ–≤
            retention_days: –°–∫–æ–ª—å–∫–æ –¥–Ω–µ–π —Ö—Ä–∞–Ω–∏—Ç—å –±—ç–∫–∞–ø—ã
        """
        self.db_path = Path(db_path)
        self.backup_dir = Path(backup_dir)
        self.retention_days = retention_days

        # –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        self.backup_dir.mkdir(parents=True, exist_ok=True)

        logging.info(f"‚úÖ BackupService –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {self.backup_dir}")

    def create_backup(self) -> Optional[str]:
        """
        –°–æ–∑–¥–∞—Ç—å —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é –ë–î.

        Returns:
            –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        try:
            if not self.db_path.exists():
                logging.error(f"‚ùå –ë–î –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {self.db_path}")
                return None

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_filename = f"backup_{timestamp}.sql.gz"
            backup_path = self.backup_dir / backup_filename

            # –°–æ–∑–¥–∞—ë–º SQL-–¥–∞–º–ø —Å–æ —Å–∂–∞—Ç–∏–µ–º
            logging.info(f"üíæ –°–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞: {backup_filename}")

            conn = sqlite3.connect(str(self.db_path))

            with gzip.open(backup_path, "wt", encoding="utf-8") as f:
                for line in conn.iterdump():
                    f.write(f"{line}\n")

            conn.close()

            # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
            file_size_mb = backup_path.stat().st_size / (1024 * 1024)

            logging.info(f"‚úÖ –ë—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω: {backup_filename} " f"({file_size_mb:.2f} MB)")

            # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤
            self._cleanup_old_backups()

            return str(backup_path)

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –±—ç–∫–∞–ø–∞: {e}", exc_info=True)
            return None

    def _cleanup_old_backups(self) -> int:
        """
        –£–¥–∞–ª–∏—Ç—å –±—ç–∫–∞–ø—ã —Å—Ç–∞—Ä—à–µ retention_days.

        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª—ë–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        """
        try:
            cutoff_date = datetime.now() - timedelta(days=self.retention_days)
            deleted_count = 0

            for backup_file in self.backup_dir.glob("backup_*.sql.gz"):
                # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞: backup_20260211_103045.sql.gz
                try:
                    date_str = backup_file.stem.split("_")[1]  # 20260211
                    time_str = backup_file.stem.split("_")[2]  # 103045
                    file_datetime = datetime.strptime(f"{date_str}_{time_str}", "%Y%m%d_%H%M%S")

                    if file_datetime < cutoff_date:
                        backup_file.unlink()
                        deleted_count += 1
                        logging.debug(f"üóëÔ∏è –£–¥–∞–ª—ë–Ω —Å—Ç–∞—Ä—ã–π –±—ç–∫–∞–ø: {backup_file.name}")

                except (ValueError, IndexError):
                    # –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                    continue

            if deleted_count > 0:
                logging.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤: {deleted_count}")

            return deleted_count

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –±—ç–∫–∞–ø–æ–≤: {e}")
            return 0

    def restore_backup(self, backup_file: str) -> bool:
        """
        –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ë–î –∏–∑ –±—ç–∫–∞–ø–∞.

        Args:
            backup_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –±—ç–∫–∞–ø–∞

        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ
        """
        try:
            backup_path = Path(backup_file)

            if not backup_path.exists():
                logging.error(f"‚ùå –§–∞–π–ª –±—ç–∫–∞–ø–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω: {backup_file}")
                return False

            # –°–æ–∑–¥–∞—ë–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é —Ç–µ–∫—É—â–µ–π –ë–î
            if self.db_path.exists():
                backup_current = self.db_path.with_suffix(".db.backup")
                shutil.copy2(self.db_path, backup_current)
                logging.info(f"üíæ –°–æ–∑–¥–∞–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: {backup_current.name}")

            logging.info(f"üîÑ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–∑: {backup_path.name}")

            # –£–¥–∞–ª—è–µ–º —Ç–µ–∫—É—â—É—é –ë–î
            if self.db_path.exists():
                self.db_path.unlink()

            # –ß–∏—Ç–∞–µ–º —Å–∂–∞—Ç—ã–π SQL-–¥–∞–º–ø
            with gzip.open(backup_path, "rt", encoding="utf-8") as f:
                sql_dump = f.read()

            # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é –ë–î –∏ –≤—ã–ø–æ–ª–Ω—è–µ–º –¥–∞–º–ø
            conn = sqlite3.connect(str(self.db_path))
            conn.executescript(sql_dump)
            conn.commit()
            conn.close()

            logging.info(f"‚úÖ –ë–î —É—Å–ø–µ—à–Ω–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∏–∑: {backup_path.name}")
            return True

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–∏: {e}", exc_info=True)
            return False

    def list_backups(self) -> List[dict]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –±—ç–∫–∞–ø–æ–≤.

        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –±—ç–∫–∞–ø–∞—Ö
        """
        backups = []

        for backup_file in sorted(self.backup_dir.glob("backup_*.sql.gz"), reverse=True):
            try:
                # –ü–∞—Ä—Å–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                date_str = backup_file.stem.split("_")[1]
                time_str = backup_file.stem.split("_")[2]
                file_datetime = datetime.strptime(f"{date_str}_{time_str}", "%Y%m%d_%H%M%S")

                file_size_mb = backup_file.stat().st_size / (1024 * 1024)

                backups.append(
                    {
                        "filename": backup_file.name,
                        "path": str(backup_file),
                        "datetime": file_datetime,
                        "size_mb": round(file_size_mb, 2),
                        "age_days": (datetime.now() - file_datetime).days,
                    }
                )

            except (ValueError, IndexError):
                continue

        return backups

    def get_stats(self) -> dict:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –±—ç–∫–∞–ø–æ–≤.

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        backups = self.list_backups()

        total_size_mb = sum(b["size_mb"] for b in backups)

        return {
            "total_backups": len(backups),
            "total_size_mb": round(total_size_mb, 2),
            "oldest_backup": backups[-1]["datetime"] if backups else None,
            "newest_backup": backups[0]["datetime"] if backups else None,
            "backup_dir": str(self.backup_dir),
        }
